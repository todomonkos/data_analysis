---
title: "<center> Data analysis for targeted marketing campaign <center>"
author: "<center> Domonkos Toth <center>"
date: "<center> `r Sys.Date()` <center>"
output:
  html_document:
    number_sections: yes
    fig_caption: yes
    toc: yes
    fig_width: 7
    fig_height: 5
    theme: cosmo
    highlight: tango
    code_folding: show
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE, 
                         comment = " ", error = FALSE, fig.align = 'center')
```

# Introduction
In recent years, the saturation of marketing messages and increasing consumer resistance have led to a decline in the effectiveness of traditional mass marketing approaches. Almost everybody have felt annoyance at one point in their lives by the overwhelming number of marketing emails in their inbox. In this context, data driven direct marketing has gained importance as a more targeted and cost-effective alternative. The present analysis draws on the dataset originally analyzed by Moro, Cortez, and Laureano (2011), which contains real-world data from a series of direct marketing campaigns conducted by a Portuguese bank. You can also access the dataset on the [UCI Machine Learning Repository](https://archive.ics.uci.edu/dataset/222/bank+marketing). The core objective of these campaigns was to promote term deposits‚Äîlong-term savings products offering fixed interest rates‚Äîto selected clients via telemarketing.

## Bank Direct Marketing: Context and Motivation
There are two main strategies available to banks and enterprises when promoting financial products:
- *Mass marketing*: targets the general public indiscriminately, often resulting in very low conversion rates (typically under 1%);
- *Directed marketing*: focuses on a specific subset of potential clients who are more likely to respond positively to the offer.
While the latter tends to be more effective in generating responses, it also comes with challenges, such as higher initial data requirements and potential concerns over customer privacy. Nonetheless, in a competitive and cost-sensitive financial environment, banks are under pressure to increase financial assets while simultaneously reducing operational costs. Directed marketing serves as a strategic response, especially when paired with data-driven insights that optimize the selection of contacts and minimize resource expenditure. The campaigns studied here offered attractive term deposits as a means of encouraging clients to invest. The underlying business goal was not only to increase subscription rates but also to do so by contacting fewer individuals, thereby improving efficiency and lowering the cost per acquisition.

## What is a Term Deposit?
A Term Deposit is a financial product where a customer deposits a fixed amount of money with a bank for a specified period at a predetermined interest rate. These instruments are considered low-risk and are especially attractive to conservative investors seeking predictable returns. Importantly, the interest rate is often higher than that of a regular savings account. The funds are usually inaccessible until the end of the term unless penalties are paid. For more detailed information on term deposits, refer to [Investopedia](https://www.investopedia.com/terms/t/termdeposit.asp).

## Analytical Framework
The study conducted by Moro et al. followed the CRISP-DM methodology‚Äîa widely adopted framework for structuring data mining projects. This includes the stages of business understanding, data understanding, data preparation, modeling, evaluation, and deployment. Their work involved multiple iterations of this process to improve model performance, using classification algorithms such as Na√Øve Bayes, Decision Trees, and Support Vector Machines (SVM). The ultimate goal was to build predictive models capable of identifying the most promising contacts, thereby enhancing marketing efficiency. The current analysis adopts a similar methodological approach using R. 

# Setup
**We import and assess the structure of the *bank* dataset:**
```{r setup}
library(readr)
data <- read.csv("/Users/todomonkos/Documents/it/github/data_analysis/targeted_advertisment/data/bank-full.csv", sep = ";", header = TRUE, stringsAsFactors = FALSE)
str(data)
```

It shows that the *bank* dataset as a `data.frame` has `r ncol(bank)` variables and `r nrow(bank)` observations. The dataset has `r ncol(bank) - 1` predictors along with the target variable `deposit` which is a binary variable with 2 levels "yes" and "no". The variables in this dataset are:

* `age`: numeric.
* `job`: type of job; categorical: "admin.", "unknown", "unemployed", "management", "housemaid", "entrepreneur", "student", "blue-collar, "self-employed", "retired", "technician", "services".
* `marital`: marital status; categorical: "married", "divorced", "single"; note: "divorced" means divorced or widowed.
* `education`: categorical: "secondary", "primary", "tertiary", "unknown".
* `default`: has credit in default?; binary: "yes","no".
* `balance`: average yearly balance, in euros; numeric.
* `housing`: has housing loan? binary: "yes", "no".
* `loan`: has personal loan? binary: "yes", "no".

Related with the last contact of the current campaign:

* `contact`: contact: contact communication type; categorical: "unknown","telephone","cellular". 
* `day`: last contact day of the month; numeric.
* `month`: last contact month of year; categorical: "jan", "feb", "mar", ..., "nov", "dec".
* `duration`: last contact duration, in seconds; numeric.

Other attributes:

* `campaign`: number of contacts performed during this campaign and for this client; numeric, includes last contact.
* `pdays`: number of days that passed by after the client was last contacted from a previous campaign; numeric, -1 means client was not previously contacted.
* `previous`: number of contacts performed before this campaign and for this client; numeric.
* `poutcome`: outcome of the previous marketing campaign; categorical: "success", "failure", "unknown", "other".

Target variable:

* `deposit`: Indicator of whether the client subscribed a term deposit; binary: "yes" or "no".





# Exploratory Data Analysis of the *bank* dataset.
```{r}
#Checking for the type of the variables
column_classes_bank <- lapply(bank, class)
classify_variable_bank <- function(class) {
  if (class %in% c("factor", "character")) {
    return("categorical")
  } else if (class == "integer") {
    return("discrete")
  } else if (class %in% c("numeric", "double")) {
    return("continuous")
  } else {
    return("other")
  }
}

variable_types <- sapply(column_classes_bank, function(cls) classify_variable_bank(cls[[1]]))
variable_types
```

## 2.3 Investigate the target variable *deposit* 
**Bar plot for the target variable *deposit* by using function ggplot()**
```{r}
ggplot(data = bank) + 
    geom_bar(aes(x = deposit), fill = c("red", "blue")) +
    labs(title = "Bar plot for the target variable 'deposit'")  
```
**Summary for the target variable *deposit* **
```{r}
summary(bank$deposit)
```
Imbalanced dataset, we have to consider this for the modelling

## 2.4 Invetigating the relationship between categorical predictors and *deposit* 

**2.4.1: Job vs Deposit**
```{r}
table(bank$deposit, bank$job, dnn = c("Deposit", "Job"))

ggplot(bank, aes(x = job, fill = deposit)) +
  geom_bar(width = 0.6) +
  scale_fill_manual(values = c("red", "blue")) +
  labs(title = "Number of Deposit Subscriptions by Job") +
  coord_cartesian(expand = TRUE) + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1))


ggplot(bank, aes(x = job, fill = deposit)) +
  geom_bar(position = "fill") +
  scale_fill_manual(values = c("red", "blue")) +
  labs(title = "Proportion of Deposit Subscriptions by Job") +
  coord_cartesian(expand = TRUE) + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

**2.4.2:Marital status vs Deposit**
```{r}
table(bank$deposit, bank$marital, dnn = c("Deposit", "Marital status"))

ggplot(bank, aes(x = marital, fill = deposit)) +
  geom_bar(width = 0.6) +
  scale_fill_manual(values = c("red", "blue")) +
  labs(title = "Number of Deposit Subscriptions by Marital Status") +
  coord_cartesian(expand = TRUE) 

ggplot(bank, aes(x = marital, fill = deposit)) +
  geom_bar(width = 0.6, position = "fill") +
  scale_fill_manual(values = c("red", "blue")) +
  labs(title = "Proportion of Deposit Subscriptions by Marital Status") +
  coord_cartesian(expand = TRUE) 
```

**2.4.3:Education vs Deposit**
```{r}
table(bank$deposit, bank$education, dnn = c("Deposit", "Education"))

ggplot(bank, aes(x = education, fill = deposit)) +
  geom_bar(width = 0.6) +
  scale_fill_manual(values = c("red", "blue")) +
  labs(title = "Number of Deposit Subscriptions by Education") +
  coord_cartesian(expand = TRUE) 

ggplot(bank, aes(x = education, fill = deposit)) +
  geom_bar(width = 0.6, position = "fill") +
  scale_fill_manual(values = c("red", "blue")) +
  labs(title = "Proportion of Deposit Subscriptions by Education") +
  coord_cartesian(expand = TRUE) 
```

**2.4.4: Default vs Deposit**
```{r}
table(bank$deposit, bank$default, dnn = c("Deposit", "Default"))

ggplot(bank, aes(x = default, fill = deposit)) +
  geom_bar(width = 0.6) +
  scale_fill_manual(values = c("red", "blue")) +
  labs(title = "Number of Deposit Subscriptions by Credit Default") +
  coord_cartesian(expand = TRUE) 

ggplot(bank, aes(x = default, fill = deposit)) +
  geom_bar(width = 0.6, position = "fill") +
  scale_fill_manual(values = c("red", "blue")) +
  labs(title = "Proportion of Deposit Subscriptions by Credit Default") +
  coord_cartesian(expand = TRUE)
```

**2.4.5: Housing loan vs Deposit**
```{r}
table(bank$deposit, bank$housing, dnn = c("Deposit", "Housing loan"))

ggplot(bank, aes(x = housing, fill = deposit)) +
  geom_bar(width = 0.6) +
  scale_fill_manual(values = c("red", "blue")) +
  labs(title = "Number of Deposit Subscriptions by Housing Loan") +
  coord_cartesian(expand = TRUE) 

ggplot(bank, aes(x = housing, fill = deposit)) +
  geom_bar(width = 0.6, position = "fill") +
  scale_fill_manual(values = c("red", "blue")) +
  labs(title = "Proportion of Deposit Subscriptions by Housing Loan") +
  coord_cartesian(expand = TRUE) 
```

**2.4.6: Personal loan vs Deposit**
```{r}
table(bank$deposit, bank$loan, dnn = c("Deposit", "Personal loan"))

ggplot(bank, aes(x = loan, fill = deposit)) +
  geom_bar(width = 0.6) +
  scale_fill_manual(values = c("red", "blue")) +
  labs(title = "Number of Deposit Subscriptions by Personal Loan") +
  coord_cartesian(expand = TRUE) 

ggplot(bank, aes(x = loan, fill = deposit)) +
  geom_bar(width =0.6, position = "fill") +
  scale_fill_manual(values = c("red", "blue")) +
  labs(title = "Proportion of Deposit Subscriptions by Personal Loan") +
  coord_cartesian(expand = TRUE) 
```

**2.4.7: Contact communication type vs Deposit**
```{r}
table(bank$deposit, bank$contact, dnn = c("Deposit", "Contact communication type"))

ggplot(bank, aes(x = contact, fill = deposit)) +
  geom_bar(width = 0.6) +
  scale_fill_manual(values = c("red", "blue")) +
  labs(title = "Number of Deposit Subscriptions by Contact Communication Type") +
  coord_cartesian(expand = TRUE) 

ggplot(bank, aes(x = contact, fill = deposit)) +
  geom_bar(width = 0.6, position = "fill") +
  scale_fill_manual(values = c("red", "blue")) +
  labs(title = "Proportion of Deposit Subscriptions by Contact Communication Type") +
  coord_cartesian(expand = TRUE) 
```

**2.4.8: Month vs Deposit**
```{r}
table(bank$deposit, bank$month, dnn = c("Deposit", "Job"))

ggplot(bank, aes(x = month, fill = deposit)) +
  geom_bar(width = 0.6) +
  scale_fill_manual(values = c("red", "blue")) +
  labs(title = "Number of Deposit Subscriptions by Month") +
  coord_cartesian(expand = TRUE) 

ggplot(bank, aes(x = month, fill = deposit)) +
  geom_bar(width = 0.6, position = "fill") +
  scale_fill_manual(values = c("red", "blue")) +
  labs(title = "Proportion of Deposit Subscriptions by Month") +
  coord_cartesian(expand = TRUE)  
```

**2.4.9: Previous campaign outcome vs Deposit**
```{r}
table(bank$deposit, bank$campaign, dnn = c("Deposit", "Previous campaign outcome"))

ggplot(bank, aes(x = poutcome, fill = deposit)) +
  geom_bar(width = 0.6) +
  scale_fill_manual(values = c("red", "blue")) +
  labs(title = "Number of Deposit Subscriptions by Previous Campaign Outcome") +
  coord_cartesian(expand = TRUE) 

ggplot(bank, aes(x = poutcome, fill = deposit)) +
  geom_bar(width = 0.6, position = "fill") +
  scale_fill_manual(values = c("red", "blue")) +
  labs(title = "Proportion of Deposit Subscriptions by Previous Campaign Outcome") +
  coord_cartesian(expand = TRUE)  
```

## 2.5  Invetigating the relationship between numerical predictors and *deposit* 

**2.5.1: Age vs Deposit**
```{r}
ggplot(bank, aes(x = age, color = deposit)) +
  geom_density() +
  labs(title = "Density Plot of Age by Deposit Status")
```

**2.5.2: Balance vs Deposit**
```{r}
ggplot(bank, aes(x = balance, color = deposit)) +
  geom_density() +
  labs(title = "Density Plot of Balance by Deposit Status")
```

**2.5.3: Contract duration vs Deposit**
```{r}
ggplot(bank) +
  geom_boxplot(aes(x = deposit, y = duration, fill = deposit)) 

ggplot(bank, aes(x = duration, color = deposit)) +
  geom_density(aes(fill = deposit, alpha = 0.1)) +
  labs(title = "Density Plot of Contract duration by Deposit Status")
```

**2.5.4: Campaign vs Deposit**
```{r}
ggplot(bank, aes(x = campaign, color = deposit)) +
  geom_density(aes(fill = deposit, alpha = 0.1)) +
  labs(title = "Density Plot of Campaign by Deposit Status")
```

**2.5.5: Pdays vs Deposit**
```{r}
ggplot(bank, aes(x = pdays, color = deposit)) +
  geom_density() +
  labs(title = "Density Plot of Pdays by Deposit Status")
```

**2.5.6: Previous contacts vs Deposit**
```{r}
ggplot(bank, aes(x = previous, color = deposit)) +
  geom_density() +
  labs(title = "Density Plot of Previous Contacts by Deposit Status")
```

## 2.6 Correlation of numeric variables 
```{r}
# Correlation matrix for numeric variables
numeric_vars <- bank[, sapply(bank, is.integer)]
correlation_matrix <- cor(numeric_vars)
ggcorrplot(correlation_matrix, type = "lower", lab = TRUE, lab_size = 3) 
```

### Chi-Square Test

In the *bank* dataset, test whether there is a relationship between the target variable ‚Äú`deposit`‚Äù and the variable ‚Äú`education`‚Äù with $\alpha=0.05$.

Null and Alternative Hypotheses:

 \[
  H_0: \text{"deposit" and "education" are independent}
  \]
   \[
  H_1: \text{"deposit" and "education" are not independent}
  \]

```{r}
contingency_table <- table(bank$deposit, bank$education)
chi_squared_result <- chisq.test(contingency_table)
chi_squared_result
```

p-value: `r round(chi_squared_result$p.value, 4)` </br>

Since the p-value is `r round(chi_squared_result$p.value, 4)`, which is less than the significance level of Œ±=0.05, we reject the null hypothesis.</br>

This indicates that there is a significant relationship between the "deposit" and "education" variables, which could suggests that the level of education may influence customers' decisions to make a deposit informing targeted marketing strategies and customer engagement efforts.

# Modelling

include: 
Using knn
logistic regression
naive bayes
decision tree

also consider sampling because of the imbalance in the categories

## Data Preparation

We partition the *bank* dataset randomly into two groups: train set (80%) and test set (20%). Here, we use the `partition()` function from the *liver* package:

```{r}
set.seed(5)

data_sets = partition(data = bank, prob = c(0.8, 0.2))

train_set = data_sets$part1
test_set  = data_sets$part2

actual_test  = test_set$deposit
```

Note that here we are using the `set.seed()` function to create reproducible results. 

We want to validate the partition by testing whether the proportion of the target variable `deposit` differs between the two data sets. We use a Two-Sample Z-Test for the difference in proportions. To run the test, we use the `prop.test()` function in **R**:
```{r}
x1 = sum(train_set$deposit == "yes")
x2 = sum(test_set $deposit == "yes")

n1 = nrow(train_set)
n2 = nrow(test_set)

prop.test(x = c(x1, x2), n = c(n1, n2))
```

Based on the output, answer the following questions:

a. **Why is the above hypothesis test suitable for the above research question? Provide your reasons.**
<br>
The Two-Sample Z-Test for proportions is a suitable hypothesis test because we want to compare the proportion of clients subscribing to a term deposit (the "yes" value) between the two datasets (train and test sets). This test helps determine if there is a statistically significant difference between the proportions of two independent groups. Since the data is categorical (binary outcome: "yes" or "no"), a proportion test is appropriate.

b. **Specify the null and alternative hypotheses?** <br>
**Null Hypothesis (H‚ÇÄ)**: The proportion of customers who subscribe to a term deposit is the same in both the train and test datasets.<br>
  \[
  H_0: \pi_1 = \pi_2
  \]
  
- **Alternative Hypothesis (H‚ÇÅ)**: The proportion of customers who subscribe to a term deposit is different between the train and test datasets. <br>
  \[
  H_1: \pi_1 \neq \pi_2
  \]
Where \(\pi_1\) is the proportion of customers subscribing in the training set, and \(\pi_2\) is the proportion of customers subscribing in the test set.

c. **Explain that you reject or do not reject the null hypothesis, at $\alpha=0.05$. What would be your statistical conclusion?** <br>
Given the **p-value = 0.1217**, which is **greater** than the significance level **ùõº = 0.05**, we **fail to reject the null hypothesis**.

d. **What would be a non-statistical interpretation of your findings in c?**
In practical terms, this means that the way we partitioned the data between training and testing groups resulted in similar proportions of customers subscribing to term deposits. Therefore, the partition is likely to represent the overall dataset well, and the training and test sets are comparable in terms of the key target variable (term deposit subscriptions). This is important for ensuring that the model is trained on data representative of what it will encounter during testing.

## Classification using the kNN algorithm

The results from the "Exploratory Data Analysis (EDA)" (from last week) indicate that the following predictors from `r ncol(bank) - 1` predictors in the *bank* dataset are important to predict `deposit`.

`age`, `default`, `balance`, `housing`, `loan`, `duration`, `campaign`, `pdays`, and `previous`.

Thus, here, based on the training dataset, we want to apply kNN algorithm, by using above predictors in our model. We use the following formula:
```{r}
formula = deposit ~ age + default + balance + housing + loan + duration + campaign + pdays + previous
```

**NOTE:** The above formula means `deposit` is the target variable and the rest of the variables in the right side of tilde ("`~`") are independent variables. 

Based on the training dataset, we want to find the k-nearest neighbor for the test data set. Here we use two different values for k (k = 3 and k = 10). We use the `kNN()` function from the *R* package **liver**:
```{r}
predict_knn_3  = kNN(formula, train = train_set, test = test_set, k = 3)

predict_knn_10 = kNN(formula, train = train_set, test = test_set, k = 10)
```

To have an overview of the prediction result, we report *Confusion Matrix* for two different values of k by using the `conf.mat` function: 
```{r}
(conf_knn_3 = conf.mat(predict_knn_3, actual_test))

(conf_knn_10 = conf.mat(predict_knn_10, actual_test))
```

We also could report *Confusion Matrix* by using the `conf.mat.plot()` command:
```{r fig.show = "hold", out.width = "50%", fig.align = 'default'}
conf.mat.plot(predict_knn_3, actual_test, main = "kNN with k = 3")

conf.mat.plot(predict_knn_10, actual_test, main = "kNN with k = 10")
```

**What do these values mean? Explain what conclusion you will draw.**
In the first *Confusion Matrix*, we set the *k=3*. The model correctly predicted 806 customers who did not subscribe to the deposit (true negative). The model incorrectly predicted 45 customers would subscribe when they did not (false positive). The model incorrectly predicted 76 customers would not subscribe when they actually did (false negative). Finally, the model correctly predicted 19 customers would subscribe to the deposit (true positive).<br>
<br>
In the second *Confusion Matrix*, we set the *k=10*. The model correctly predicted 834 customers who did not subscribe to the deposit (true negative). The model incorrectly predicted 17 customers would subscribe when they did not (false positive). The model incorrectly predicted 74 customers would not subscribe when they actually did (false negative). Finally, the model correctly predicted 21 customers would subscribe to the deposit (true positive).<br>
<br>
Based on these findings we can calculate the accuracy of the model with different values for k. 
```{r}
# Calculate accuracy for k = 3
accuracy_knn_3 <- mean(predict_knn_3 == actual_test)
print(accuracy_knn_3)
```

```{r}
# Calculate accuracy for k = 10
accuracy_knn_10 <- mean(predict_knn_10 == actual_test)
print(accuracy_knn_10)
```
Thus, increasing k from 3 to 10 leads to better accuracy, suggesting that using 10 neighbors is more effective for this dataset.

# Model evaluation by MSE

To evaluate the accuracy of the predictions, we calculate the Mean Square Error (MSE) by using the `mse()` function from the **liver** package:

```{r}
MSE_3 = mse(predict_knn_3, actual_test)
MSE_3 

MSE_10 = mse(predict_knn_10, actual_test)
MSE_10
```

**For the case k=3, the MSE = `r round(MSE_3 , 3)` and for the case k = 10, the MSE = `r round(MSE_10, 3)`. What do these values mean? Explain what conclusion you will draw.**
The MSE provides a way to measure how far the predicted values are from the actual values. A lower MSE indicates better performance, meaning the predictions are closer to the actual outcomes. Since the MSE for k=10 (`r round(MSE_10 , 3)`) is lower than for k=3 (`r round(MSE_3 , 3)`), we can conclude that the model with k=10 performs better in predicting whether a client will subscribe to a term deposit (the target variable). 

## Visualizing Model Performance by ROC curve

To report the ROC curve, we need the probability of our classification prediction. We can have it by using:
```{r}
prob_knn_3  = kNN(formula, train = train_set, test = test_set, k = 3 , type = "prob")[, 1]

prob_knn_10 = kNN(formula, train = train_set, test = test_set, k = 10, type = "prob")[, 1]
```

To visualize the model performance, we could report the ROC curve plot by using the `plot.roc()` function from the **pROC** package:

```{r}
library(pROC)
roc_knn_3 = roc(actual_test, prob_knn_3)

roc_knn_10 = roc(actual_test, prob_knn_10)

ggroc(list(roc_knn_3, roc_knn_10), size = 0.8) + 
    theme_minimal() + ggtitle("ROC plots with AUC for kNN") +
    scale_color_manual(values = c("red", "blue"), 
    labels = c(paste("k=3 ; AUC=", round(auc(roc_knn_3), 3)),
                paste("k=10; AUC=", round(auc(roc_knn_10), 3))
             )) +
    theme(legend.title = element_blank()) +
    theme(legend.position = c(.7, .3), text = element_text(size = 17))
```


In the above plot, '<span style="color:red">red</span>' curve is for the case k = 3 and the '<span style="color:blue">blue</span>' curve is for the case k = 10.

**Explain what conclusion you will draw. Do we need to report AUC (Area Under the Curve) as well?**
The ROC curve shows the performance of two k-nearest neighbor (kNN) models for predicting the target variable 'deposit'. However, we should also report the AUC in order to provide a single metric to evaluate the performance of the models. 

*AUC*
```{r}
# Get the AUC for k = 3
auc_knn_3 = auc(roc_knn_3)
print(paste("AUC for k=3:", round(auc_knn_3, 3)))
```

```{r}
# Get the AUC for k = 10
auc_knn_10 = auc(roc_knn_10)
print(paste("AUC for k=10:", round(auc_knn_10, 3)))
```
Based on the AUC values, the Red Curve (k = 3, `r auc_knn_3`) indicates a moderate performance. This model is better than random guessing (AUC = 0.5), but it is not highly accurate in distinguishing between depositors and non-depositors. <br>
The Blue Curve (k = 10, `r auc_knn_10``) is higher at 0.797, which suggests that this model performs better than the model with k=3. It has a higher capability of correctly predicting the target class compared to the smaller k value, making it a preferable choice between the two models. 

## kNN algorithm with data transformation

The predictors that we used in the previous question, do not have the same scale. For example, variable `duration` change between `r min(bank$duration)` and `r max(bank$duration)`, whereas the variable `loan` is binary. In this case, the values of variable `duration` will overwhelm the contribution of the variable `loan`. To avoid this situation we use normalization. So, we use min-max normalization and transfer the predictors. 

Now, we find the k-nearest neighbor for the test set, based on the training dataset, for the k = 10:

```{r}
predict_knn_10_trans = kNN(formula, train = train_set, test = test_set, transform = "minmax", k = 10)

conf.mat.plot(predict_knn_10_trans, actual_test)
```

## ROC curve and AUC for transformed data

To report the ROC curve, we need the probability of our classification prediction. We can have it by using:
```{r}
prob_knn_10 = kNN(formula, train = train_set, test = test_set, k = 10, type = "prob")[, 1]

prob_knn_10_trans = kNN(formula, train = train_set, test = test_set, transform = "minmax", k = 10, type = "prob")[, 1]
```

To visualize the model performance between the raw data and the transformed data, we could report the ROC curve plot as well as AUC (Area Under the Curve) by using the `plot.roc()` function from the **pROC** package:

```{r}
roc_knn_10 = roc(actual_test, prob_knn_10)

roc_knn_10_trans = roc(actual_test, prob_knn_10_trans)

ggroc(list(roc_knn_10, roc_knn_10_trans), size = 0.8) + 
    theme_minimal() + ggtitle("ROC plots with AUC for kNN") +
    scale_color_manual(values = c("red", "blue"), 
      labels = c(paste("Raw data             ; AUC=", round(auc(roc_knn_10), 3)), 
                  paste("Transformed data; AUC=", round(auc(roc_knn_10_trans), 3)))) +
  theme(legend.title = element_blank()) +
  theme(legend.position = c(.7, .3), text = element_text(size = 17))
```

In the above plot black curve is for the *raw* dataset and the red curve is for the *transformed* dataset.

**Explain what conclusion you will draw. Based on the values of AUC (Area Under the Curve), explain what conclusion you will draw.**<br>
The ROC curve comparison shows that the kNN model with transformed data has a higher AUC (0.814) compared to the model with raw data (AUC = 0.797), indicating improved performance. Normalization helps balance the influence of features with different scales, such as `duration` and `loan`, leading to better classification accuracy. The higher AUC for the transformed data suggests it is better at distinguishing between positive and negative classes, making the transformed data model more effective.

## Optimal value of k for the kNN algorithm

In the previous questions, for finding the k-nearest neighbor for the test set, we set k = 10. But why 10? Here, we want to find out the optimal value of k based on our dataset. 

To find out the optimal value of `k` based on *Error Rate*, for the different values of k from 1 to 30, we run the k-nearest neighbor for the test set and compute the *Error Rate* for these models, by running `kNN.plot()` command 

```{r}
kNN.plot(formula, train = train_set, test = test_set, transform = "minmax", 
          k.max = 30, set.seed = 7)
```

**Based on the plot, what value of k is optimal? Provide your reasons.**
Based on the plot, a k-value of 8 results in the most accurate predictions for the test set showing the lowest error rate, with fewer misclassifications than other values of k.